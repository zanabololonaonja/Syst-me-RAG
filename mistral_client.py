import requests
import streamlit as st

# -----------------------
# CONFIGURATION MISTRAL
# -----------------------

MISTRAL_API_URL = "https://api.mistral.ai/v1/chat/completions"
MISTRAL_API_KEY = "uXm9QqcIgCCylmcePxiZacnYdICgSouW"
MISTRAL_MODEL = "mistral-tiny"

def get_mistral_api_key():
    return MISTRAL_API_KEY

def call_mistral_api(context_chunks_with_metadata, question, conversation_history=[]):
    """Appelle l'API Mistral avec un prompt amÃ©liorÃ© pour une meilleure intelligence"""
    
    headers = {
        "Authorization": f"Bearer {MISTRAL_API_KEY}",
        "Content-Type": "application/json"
    }
    
    # Construction du prompt ultra-optimisÃ© pour l'analyse documentaire
    system_prompt = """Tu es un expert en analyse documentaire avec des capacitÃ©s de raisonnement avancÃ©es.

ğŸ¯ TON RÃ”LE :
Analyser profondÃ©ment les documents pour fournir des rÃ©ponses intelligentes, contextuelles et prÃ©cises.

ğŸ” MÃ‰THODOLOGIE :
1. ANALYSE MULTI-NIVEAU : Comprendre le contexte global et les dÃ©tails spÃ©cifiques
2. RAISONNEMENT DÃ‰DUCTIF : Faire des liens entre les informations
3. SYNTHÃˆSE INTELLIGENTE : RÃ©sumer sans perdre l'essentiel
4. CONTEXTE DOCUMENTAIRE : Utiliser les mÃ©tadonnÃ©es (sources, documents)

ğŸ“ RÃˆGLES STRICTES :
âœ… UTILISE exclusivement le contexte fourni
âœ… SOIS prÃ©cis, dÃ©taillÃ© et contextuel
âœ… FAIS des dÃ©ductions logiques basÃ©es sur les informations
âœ… STRUCTURE tes rÃ©ponses de maniÃ¨re claire
âœ… MENTIONNE les documents sources quand c'est pertinent
âœ… ADAPTE ton style Ã  la complexitÃ© de la question

ğŸš« INTERDICTIONS :
âŒ JAMAIS d'inventions ou d'hallucinations
âŒ JAMAIS d'informations extÃ©rieures au contexte
âŒ JAMAIS de rÃ©ponses vagues ou gÃ©nÃ©riques

Ton objectif : Ãªtre l'analyste documentaire le plus compÃ©tent et fiable."""

    messages = [{"role": "system", "content": system_prompt}]
    
    # Ajout de l'historique rÃ©cent avec contexte conversationnel
    for msg in conversation_history[-3:]:  # Garde les 3 derniers Ã©changes
        if msg["type"] == "question":
            messages.append({"role": "user", "content": msg["text"]})
        else:
            messages.append({"role": "assistant", "content": msg["text"]})
    
    # PrÃ©paration du contexte enrichi avec mÃ©tadonnÃ©es
    context_parts = []
    for i, chunk_data in enumerate(context_chunks_with_metadata[:6]):  # 6 chunks max
        source_info = f"[Source: {chunk_data['source']}]"
        context_parts.append(f"{source_info}\n{chunk_data['text']}")
    
    context_text = "\n\n" + "="*50 + "\n".join(context_parts) + "\n" + "="*50
    
    user_content = f"""## ğŸ“š CONTEXTE DOCUMENTAIRE COMPLET :
{context_text}

## â“ QUESTION Ã€ ANALYSER :
{question}

## ğŸ¯ INSTRUCTIONS :
En tant qu'expert en analyse documentaire, fournis une rÃ©ponse :
- BasÃ©e UNIQUEMENT sur le contexte ci-dessus
- PrÃ©cise, dÃ©taillÃ©e et bien structurÃ©e
- Avec un raisonnement logique et clair
- AdaptÃ©e Ã  la complexitÃ© de la question
- Mentionnant les sources documentaires quand c'est pertinent"""

    messages.append({"role": "user", "content": user_content})
    
    payload = {
        "model": MISTRAL_MODEL,
        "messages": messages,
        "temperature": 0.2,
        "max_tokens": 1200,
        "top_p": 0.9
    }
    
    try:
        response = requests.post(MISTRAL_API_URL, headers=headers, json=payload, timeout=45)
        
        if response.status_code == 429:
            return "ğŸ”„ Trop de requÃªtes. Veuillez patienter quelques instants avant de rÃ©essayer."
        elif response.status_code == 401:
            return "ğŸ” ProblÃ¨me d'authentification. ClÃ© API invalide."
        elif response.status_code == 403:
            return "ğŸš« AccÃ¨s non autorisÃ©. VÃ©rifiez vos permissions API."
        elif response.status_code == 400:
            return "âš ï¸ RequÃªte mal formÃ©e. Le service peut Ãªtre temporairement surchargÃ©."
        
        response.raise_for_status()
        
        result = response.json()
        return result["choices"][0]["message"]["content"]
        
    except requests.exceptions.Timeout:
        return "â° DÃ©lai de rÃ©ponse dÃ©passÃ©. Le service met plus de temps Ã  rÃ©pondre en raison de la complexitÃ© de l'analyse."
    except Exception as e:
        return f"âŒ Erreur technique: {str(e)}"

def smart_text_analysis_with_mistral(context_chunks_with_metadata, question, conversation_history):
    """Analyse intelligente avec Mistral pour plusieurs documents"""
    if not context_chunks_with_metadata:
        return "ğŸ” Aucune information pertinente trouvÃ©e dans les documents pour rÃ©pondre Ã  cette question. Essayez de reformuler ou vÃ©rifiez que les documents contiennent bien ces informations."
    
    # Questions trÃ¨s simples qu'on peut traiter sans LLM
    question_lower = question.lower()
    
    if any(word in question_lower for word in ['bonjour', 'salut', 'hello', 'coucou']):
        return "ğŸ‘‹ Bonjour ! Je suis votre assistant IA spÃ©cialisÃ© dans l'analyse documentaire. Importez vos documents et posez-moi toutes vos questions !"
    
    elif any(word in question_lower for word in ['merci', 'thanks']):
        return "âœ¨ Je vous en prie ! N'hÃ©sitez pas si vous avez d'autres questions sur vos documents."
    
    elif any(word in question_lower for word in ['aide', 'help', 'comment Ã§a marche']):
        return """
### ğŸ¯ Guide d'Utilisation Complet

**ğŸ“¤ IMPORTATION :**
- Allez dans l'onglet 'Documents'
- Uploader jusqu'Ã  5 fichiers PDF ou DOCX
- Cliquez sur 'Indexer les documents'

**ğŸ’¬ CONVERSATION INTELLIGENTE :**
- Posez des questions complexes sur le contenu
- Demandez des analyses, rÃ©sumÃ©s, comparaisons
- Interrogez sur des points spÃ©cifiques ou gÃ©nÃ©raux

**ğŸ” TECHNOLOGIES UTILISÃ‰ES :**
- âœ… **FAISS** : Recherche vectorielle avancÃ©e
- âœ… **LangChain** : Framework d'IA professionnel
- âœ… **Sentence Transformers** : Embeddings sÃ©mantiques
- âœ… **Mistral AI** : ModÃ¨le de langage performant

**FONCTIONNALITÃ‰S AVANCÃ‰ES :**
- Recherche sÃ©mantique par similaritÃ© vectorielle
- Analyse multi-documents intelligente
- Raisonnement contextuel approfondi
- RÃ©ponses dÃ©taillÃ©es et structurÃ©es
        """
    
    else:
        # Pour toutes les autres questions, on utilise Mistral avec le contexte enrichi
        return call_mistral_api(context_chunks_with_metadata, question, conversation_history)